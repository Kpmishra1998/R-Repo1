<!DOCTYPE html>
<html>
  <head>
    <title>Inference and Randomization</title>
    <meta charset="utf-8">
    <meta name="author" content="Edward Rubin" />
    <meta name="date" content="2019-06-03" />
    <link href="11Randomization_NoPause_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="11Randomization_NoPause_files/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="11Randomization_NoPause_files/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="my-css.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Inference and Randomization
## EC 425/525, Set 11
### Edward Rubin
### 03 June 2019

---

class: inverse, middle



$$
`\begin{align}
  \def\ci{\perp\mkern-10mu\perp}
\end{align}`
$$


# Prologue

---
name: schedule

# Schedule

## Last time

An analytical solution to cluter-robust inference

## Today

Inference using (re)randomization .super[.pink[†]]

.footnote[
.pink[†] Parts of these notes closely follow notes from [Kosuke Imai](https://imai.fas.harvard.edu).
]

## Upcoming

The end is near. As is the final.
---
layout: true
# Inference and (re)randomization

---
class: inverse, middle
---
## Inference recap

Our inference techniques have focused on (asymptotic) .attn[analytical methods].

1. Choose (or derive) an estimator

2. Derived the estimator's (asymptotic) distribution.super[.pink[†]]

3. Construct confidence intervals or hypothesis tests

.footnote[
.pink[†] And, consequently, standard errors.
]
---
name: resampling
## Resampling

.attn[Resampling methods] offers a different, more computationally intense (less asymptoically intense) approach.


A .attn[resampling method] involves repeatedly drawing samples (*resampling*) from a dataset and refitting the model of interest on each sample. We can learn about the behavior of the model through its performance across the many iterations..super[.pink[†]]

.footnote[
.pink[†] This approach is very similar to our Monte Carlo simulations, except that we will sample *with replacement* from a single dataset.
]


.note[Common implementations:] Bootstrap (and jackknife), cross validation, permutation tests/randomization inference

---
layout: true
# The bootstrap

---
name: boot
class: inverse, middle
---
## Basics

.attn[Bootstrapping] resamples, .it[with replacement], from the original dataset.


- In each sample, we apply our estimator.
- Then, we consider the distribution/properties of these estimates.

This resampling helps us better understand the uncertainty associated with our estimator (within the current data setting).

---
name: boot-formal
## More formally

Let's formalize the bootstrap a bit.
- `\(Z\)` denotes our original dataset (_e.g._, `\(Z = \left[ \text{Y} \mid \text{X} \right]\)` in our standard setup).

- `\(\hat\alpha(Z)\)` refers to the estimate for `\(\alpha\)` derived from our dataset `\(Z\)`.

- We draw `\(B\)` bootstrap samples `\(b\in \left\{ 1,\,\ldots,\, B \right\}\)`.

- `\(Z^{\star 1}\)` represents our first bootstrap sample `\(\left( b=1 \right)\)`.

- `\(\hat{\alpha}^{\star 1} = \hat\alpha(Z^{\star1})\)` is our estimator evaluated on the first bootstrap sample.


The .attn[bootstrapped standard error] of `\(\hat\alpha\)` is the standard deviation of the `\(\hat\alpha^{\star b}\)`

$$
`\begin{align}
  \mathop{\text{SE}_{B}}\left( \hat\alpha \right) = \sqrt{\dfrac{1}{B} \sum_{b=1}^{B} \left( \hat\alpha^{\star b} - \dfrac{1}{B} \sum_{\ell=1}^{B} \hat\alpha^{\star \ell} \right)^2}
\end{align}`
$$
---
exclude: true



---
name: boot-graph
## More graphically

.thin-left[
`$$Z$$`
&lt;img src="11Randomization_NoPause_files/figure-html/g1-boot0-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

`$$\hat\beta = 0.653$$`

&lt;img src="11Randomization_NoPause_files/figure-html/g2-boot0-1.svg" width="100%" style="display: block; margin: auto;" /&gt;
]


.thin-left[
`$$Z^{\star 1}$$`
&lt;img src="11Randomization_NoPause_files/figure-html/g1-boot1-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

`$$\hat\beta = -0.961$$`

&lt;img src="11Randomization_NoPause_files/figure-html/g2-boot1-1.svg" width="100%" style="display: block; margin: auto;" /&gt;
]


.thin-left[
`$$Z^{\star 2}$$`
&lt;img src="11Randomization_NoPause_files/figure-html/g1-boot2-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

`$$\hat\beta = 0.51$$`

&lt;img src="11Randomization_NoPause_files/figure-html/g2-boot2-1.svg" width="100%" style="display: block; margin: auto;" /&gt;
]


.left5[
&lt;br&gt;&lt;br&gt;&lt;br&gt;⋯
]

.thin-left[
`$$Z^{\star B}$$`
&lt;img src="11Randomization_NoPause_files/figure-html/g1-boot3-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

`$$\hat\beta = 1.338$$`

&lt;img src="11Randomization_NoPause_files/figure-html/g2-boot3-1.svg" width="100%" style="display: block; margin: auto;" /&gt;
]

---

Running this bootstrap 10,000 times


```r
plan(multiprocess, workers = 10)
# Set a seed
set.seed(123)
# Run the simulation 1e4 times
boot_df &lt;- future_map_dfr(
  # Repeat sample size 100 for 1e4 times
  rep(n, 1e4),
  # Our function
  function(n) {
    # Estimates via bootstrap
    est &lt;- lm(y ~ x, data = z[sample(1:n, n, replace = T), ])
    # Return a tibble
    data.frame(int = est$coefficients[1], coef = est$coefficients[2])
  },
  # Let furrr know we want to set a seed
  .options = future_options(seed = T)
)
```
---
layout: false
class: clear, middle

&lt;img src="11Randomization_NoPause_files/figure-html/boot-full-graph-1.png" style="display: block; margin: auto;" /&gt;

---
layout: true
# The bootstrap

---
## Comparison

In this 10,000-sample bootstrap, we calculate a standard error for `\(\hat\beta_1\)` of approximately 0.777.


If we go the old-fashioned OLS route `\(\left( s^2 \left(\text{X}'\text{X}\right)^2 \right)\)`, we estimate 0.673.

Not bad.
---
layout: true
# Permutation tests

---
name: perm
class: inverse, middle
---
name: perm-motive
## Motivation

Consider the null hypothesis of *no average treatment effect*, _i.e._,
.center[
H.sub[o]:  `\(\overline{\text{Y}}_{0} = \overline{\text{Y}}_{1}  \quad \left(\implies \overline{\tau}=0 \right)\)`
]


We've discussed how randomization avoids the pitfalls of selection bias.


Randomization can also clarify inference—helping quantify uncertainty.


.qa[Q] How?


.qa[A] We know exactly how the randomness happened (we assigned it), so we don't need parametric assumptions to derive a distribution under H.sub[o]!
&lt;br&gt; We use the .hi[experimental design], rather than a probability model.
---
name: perm-tea
## Tea drinkers

.ex[Classic example] Sir R. A. Fisher had a colleague who claimed to be able to tell whether the tea was poured into milk *or* milk was poured into the tea..super[.pink[†]]

.footnote[
.pink[†] Don't worry, Fisher is known for more than this one experiment.
]


Being the friend he was, Fisher designed an experiment to determine whether his colleague was telling the truth.


Fisher randomized the order of 8 cups of tea:

- 4 cups with .hi-purple[m]ilk added first
- 4 cups with .hi-pink[t]ea added first


Vindication! His colleague got all 8 correct.
&lt;br&gt;.qa[Q] With random guessing, how likely is correctly guessing all 8 cups?
---
## Tea drinkers 2

.qa[Q] With random guessing, how likely is correctly guessing all 8 cups?


This question reflects our understanding of a .hi-slate[*p*-value].

If Fisher's colleague had no ability and simply guessed (H.sub[o]), what is the probability she would have guessed all 8 cups correctly?


Fisher's H.sub[o]: the answers were unrelated to the cups' actual contents.

Under this hypothesis, we can re-randomize the cups and see how many times her answer was perfectly correct.


This is the idea behind .attn[permutation testing] and .attn[randomization inference].
---
## Tea drinkers with a vengeance

.left10.center[
.note[Cup.sub[]]
&lt;br&gt;1
&lt;br&gt;2
&lt;br&gt;3
&lt;br&gt;4
&lt;br&gt;5
&lt;br&gt;6
&lt;br&gt;7
&lt;br&gt;8
]
.left10.center[
.note[Guess.sub[]]
&lt;br&gt;.hi-purple[m]
&lt;br&gt;.hi-pink[t]
&lt;br&gt;.hi-pink[t]
&lt;br&gt;.hi-purple[m]
&lt;br&gt;.hi-purple[m]
&lt;br&gt;.hi-pink[t]
&lt;br&gt;.hi-pink[t]
&lt;br&gt;.hi-purple[m]
]
.left10.center[
.note[Truth.sub[]]
&lt;br&gt;.hi-purple[m]
&lt;br&gt;.hi-pink[t]
&lt;br&gt;.hi-pink[t]
&lt;br&gt;.hi-purple[m]
&lt;br&gt;.hi-purple[m]
&lt;br&gt;.hi-pink[t]
&lt;br&gt;.hi-pink[t]
&lt;br&gt;.hi-purple[m]
&lt;br&gt;.smaller[8/8]
]
.left10.center[
.note[P.sub[1]]
&lt;br&gt;.hi-purple[m]
&lt;br&gt;.hi-purple.st[m]
&lt;br&gt;.hi-purple.st[m]
&lt;br&gt;.hi-purple[m]
&lt;br&gt;.hi-pink.st[t]
&lt;br&gt;.hi-pink[t]
&lt;br&gt;.hi-pink[t]
&lt;br&gt;.hi-pink.st[t]
&lt;br&gt;.smaller[4/8]
]
.left10.center[
.note[P.sub[2]]
&lt;br&gt;.hi-purple[m]
&lt;br&gt;.hi-purple.st[m]
&lt;br&gt;.hi-purple.st[m]
&lt;br&gt;.hi-pink.st[t]
&lt;br&gt;.hi-purple[m]
&lt;br&gt;.hi-pink[t]
&lt;br&gt;.hi-pink[t]
&lt;br&gt;.hi-pink.st[t]
&lt;br&gt;.smaller[4/8]
]
.left10.center[
.note[P.sub[3]]
&lt;br&gt;.hi-purple[m]
&lt;br&gt;.hi-purple.st[m]
&lt;br&gt;.hi-purple.st[m]
&lt;br&gt;.hi-pink.st[t]
&lt;br&gt;.hi-pink.st[t]
&lt;br&gt;.hi-purple.st[m]
&lt;br&gt;.hi-pink[t]
&lt;br&gt;.hi-pink.st[t]
&lt;br&gt;.smaller[2/8]
]
.left5.center[
.note[⋯]
]
.left10.center[
.note[P.sub[70]]
&lt;br&gt;.hi-pink.st[t]
&lt;br&gt;.hi-pink[t]
&lt;br&gt;.hi-pink[t]
&lt;br&gt;.hi-pink.st[t]
&lt;br&gt;.hi-purple[m]
&lt;br&gt;.hi-purple.st[m]
&lt;br&gt;.hi-purple.st[m]
&lt;br&gt;.hi-purple[m]
&lt;br&gt;.smaller[4/8]
]
.left30.pad-left[
&lt;br&gt;
&lt;img src="11Randomization_NoPause_files/figure-html/graph-tea-1.svg" width="100%" style="display: block; margin: auto;" /&gt;
]


.clear-up[
So our permutation-test-based *p*-value is 1/70 `\(\approx\)` 0.0143. `\(\implies\)` Reject H.sub[o].
]
---
name: perm-gen
## Generalization

The procedure for permutation-based hypothesis testing.super[.pink[†]] is the same as our "standard" asymptotic-based hypothesis testing.

.footnote[
.pink[†] Also called *Fisher's exact test*, as you get exact *p*-values.
]


1. .hi-slate[Define hypotheses], H.sub[o] and H.sub[a].
1. Choose our .hi-slate[rejection threshold] `\(\alpha\)` (tolerated type-I error rate).
1. Choose a .hi-slate[test statistic] that is a function of our sample.
1. Derive/calculate the .hi-slate[test statistic's distribution .it[under H.sub[o]]].
1. .hi-slate[Compute the *p*-value] by comparing test stat. to its H.sub[o] distribution.
1. .hi-slate[Conclusions]—reject or fail to reject H.sub[o].


.note[The difference:] Permutation tests use the randomization's mechanism to construct the test-statistic's exact distribution under H.sub[o].

---
## More generally

Fisher focused on testing a .attn[sharp null hypothesis]—no effect *for anyone*, _i.e._,
.center[
H.sub[o]: `\(\text{Y}_{1i} - \text{Y}_{0i} = 0 \enspace \forall i \quad \left( \implies \tau_i = 0 \enspace \forall i \right)\)`
]
against an alternative hypothesis that someone has a non-zero effect
.center[
H.sub[a]: `\(\enspace \text{Y}_{1i} - \text{Y}_{0i} \neq 0\)` for some `\(i\)` `\(\left( \implies \exists i \enspace \text{s.t.} \enspace \tau_i \neq 0\right)\)`
]


A .attn[sharp null hypothesis] is specified *for all individuals*, *e.g.*,
.center[
H.sub[o]: `\(\text{Y}_{1i} - \text{Y}_{0i} = C \enspace \forall i\)`
]

which differs from the ATE-based nulls that we normally consider, *e.g.*,
.center[
H.sub[o]: `\(\mathop{E}\left[\text{Y}_{1i} - \text{Y}_{0i}\right] = C\)`.
]

---
## On average

The sharp null was central to Fisher's interpretation.

[Neyman *et al.* (1935)](https://www-jstor-org.libproxy.uoregon.edu/stable/2983637) extended.super[.pink[†]] this idea of permutation-based tests to the average treatment effect (testing H.sub[o]: `\(\mathop{E}\left[ \text{Y}_{1i} \right] - \mathop{E}\left[ \text{Y}_{0i} \right] = 0\)`).

Neyman and others also added standard errors and confidence intervals.

.footnote[
.pink[†] Fisher, paraphrased: .bigger[🤬]
&lt;br&gt;.pink[††] *Permutation tests* and *Randomization inference* are not the most strictly defined terms.
]


These extensions have come to be known as .attn[randomization inference]..super[.pink[††]]
---
layout: true
# Randomization inference

---
class: inverse, middle
name: random
---
name: random-insight
## Key insight

Our estimate (or test statistic) is a function of

1. individuals' responses `\(\left( \text{Y}_{i} \right)\)`
2. individuals' treatment assignments `\(\left( \text{D}_{i} \right)\)`
---
layout: false
# Test statistics
## (Which?)

We still need to choose a test statistic on which we base the *p*-value.

- The .hi-slate[actual estimate]—difference in means or coefficient
- .hi-slate[Transformed estimates]
- .hi-slate[Quantiles] (*e.g.*, the median)
- .hi-slate[_t_ statistic]
- .hi-slate[Rank] statistics


---
layout: true
# Randomization and clustering

---
class: inverse, middle
name: clustering
---
## The plot thickens

Permutation tests and randomization inference both work because we know.super[.pink[†]] the process through which treatment was randomly assigned.

.footnote[
.pink[†] Or claim to understand.
]


If treatment is correlated within groups, then our bootstraps, permutations, and re-randomizations need to reflect this dependence.



---
layout: false
# Table of contents

.col-left[
#### Admin
.smaller[
1. [Schedule](#schedule)
]
]

.col-right[
#### Inference and randomization
.smaller[
1. [Resampling](#resampling)
1. [The bootstrap](#boot)
  - [Basics](#boot)
  - [Semi-formally](#boot-formal)
  - [Graphically](#boot-graph)
1. [Permutation tests](#perm)
  - [Motivation](#perm-motive)
  - [Tea tests](#perm-tea)
  - [Generalization](#perm-gen)
1. [Randomization inference](#random)
  - [Basics](#random-insight)
1. [Clustering](#clustering)
]
]
---
exclude: true
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
